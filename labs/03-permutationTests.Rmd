---
title: "Lab 3: Introduction to Hypothesis Testing"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

## 0. Intro

Welcome to Lab 3!

Today's lab will explore the idea of hypothesis testing using random permutations. This technique is described in the chapter 4 of the textbook, in [John Rauser's keynote address at Strata + Hadoop 2014](https://youtu.be/5Dnw46eC-0o), and is used often in practice.

### Administrative details
Lab submissions are due by DAY, MONTH ## at TIME PM...

## 1. Comparing Two Groups

Many studies generate a table that describes multiple attributes for each element in a sample of a population. One important step in studying some aspect of the world via such a sample is to identify associations. An association between a treatment attribute and an outcome attribute in a population is any relation between them: the outcome varies in some way with the treatment.

In a random sample, the outcome may appear associated with the treatment because there is in fact an association in the population, or simply because the sample happened to come out that way. The purpose of statistical hypothesis testing is to account quantitatively for the possibility that two attributes may appear related in a sample even though they are not related in the population.

In this lab, we will review the permutation test techique from [John Rauser's keynote address at Strata + Hadoop 2014](https://youtu.be/5Dnw46eC-0o), investigating how to formalize this test and implement it in R. The data are based on a study conducted in 2010...

The rows describe individual people who all participate in a two-person heterosexual relationship. The columns describe:

- **id**: An identifier for each participant
- **treatment**: Consumption of a liter of `beer` or a liter of `water`
- **count**: The number of mosquitos...

Here are some statistics about this data set.



### 1.1. Contingency Tables

Before conducting a statistical test for whether a sample association is likely to be due to chance (as opposed to an association in the population), we can use visualization to identify some possible associations.


## 2. Random Permutations

There is no single threshold for a high (or low) total variation distance. Instead, we compare the observed test statistic to a distribution that is generated empirically by randomly permuting the values in the data. 

The purpose of this comparison is to help us choose between two hypotheses:

<u>Null hypothesis:</u>: The observed difference between distributions for two conditions is due to chance because we sampled at random to collect the data.

<u>Alternative hypothesis:</u>: The observed difference is not due to chance, but instead due to an association in the population.

Both hypotheses assume that the data was in fact sampled at random from the population.  A permutation test generates samples that look like the samples we'd see if the null hypothesis were true.

The online textbook provides [an implementation of a permutation test using total variation distance as the test statistic](http://www.inferentialthinking.com/chapter5/permutation.html#Generalizing-Our-Hypothesis-Test). Below, you will extend it to other test statistics.


### 2.1. Hypothesis Tests

Each hypothesis test has four steps. 

**Step 1.** is to state the null and alternative hypotheses. For example, if we are intereted in whether married and unmarried couples rate their relationships differently, we would state the following:

<u>Null hypothesis:</u> The difference between how married and unmarried couples rate their relationships is due to the randomness introduced by sampling the data from the population

The alternative is an explanation that is exclusive of the null hypothesis: something is going on more than just random chance from sampling.

<u>Alternative hypothesis:</u> The difference between how married and unmarried couples rate their relationships is not due to chance, but instead due to an association in the population.

**Step 2.** is to select a test statistic for evaluating the null hypothesis and compute it on our observed data.  The test statistic should be something that generally looks one way if the null hypothesis is true and another way if the alternative hypothesis is true. 

<u>Test statistic:</u> The total variation distance between the distributions of relationship ratings for two conditions: married and unmarried couples.

```{r}
## CODE
```

**Step 3.** is to estimate the probability distribution of this statistic under the null hypothesis. Given only a sample, we can't draw new samples directly from the population. Instead, we randomly permute the pairings of conditions and values to see how the test statistic would vary for a sample of the given size, the split between conditions, and the observed proportions of values.

```{r}
## CODE
```

**Step 4.** is to interpret the result and draw a conclusion. A P-value of 0.05 or below is conventionally called "statistically significant" and a P-value of 0.01 or below is conventionally called "highly statistically significant", although these thresholds are arbitrary.




